<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A MODERN DIVE into Data with R</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Getting away from the traditional introductory statistics curriculum, more focused on reproducible research and modern data analysis techniques and tools">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="A MODERN DIVE into Data with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Getting away from the traditional introductory statistics curriculum, more focused on reproducible research and modern data analysis techniques and tools" />
  <meta name="github-repo" content="ismayc/moderndiver-source" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A MODERN DIVE into Data with R" />
  
  <meta name="twitter:description" content="Getting away from the traditional introductory statistics curriculum, more focused on reproducible research and modern data analysis techniques and tools" />
  

<meta name="author" content="Chester Ismay">

<meta name="date" content="2016-09-02">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="5-manip.html">
<link rel="next" href="7-hypo.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.7/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/dygraphs-binding-1.1.1.1/dygraphs.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i><b>1.1</b> Colophon</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-intro.html"><a href="2-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="2-intro.html"><a href="2-intro.html#preamble"><i class="fa fa-check"></i><b>2.1</b> Preamble</a></li>
<li class="chapter" data-level="2.2" data-path="2-intro.html"><a href="2-intro.html#two-driving-data-sources"><i class="fa fa-check"></i><b>2.2</b> Two driving data sources</a></li>
<li class="chapter" data-level="2.3" data-path="2-intro.html"><a href="2-intro.html#datascience-pipeline"><i class="fa fa-check"></i><b>2.3</b> Data/science pipeline</a></li>
<li class="chapter" data-level="2.4" data-path="2-intro.html"><a href="2-intro.html#reproducibility"><i class="fa fa-check"></i><b>2.4</b> Reproducibility</a></li>
<li class="chapter" data-level="2.5" data-path="2-intro.html"><a href="2-intro.html#who-is-this-book-for"><i class="fa fa-check"></i><b>2.5</b> Who is this book for?</a></li>
</ul></li>
<li class="part"><span><b>Data Exploration</b></span></li>
<li class="chapter" data-level="3" data-path="3-tidy.html"><a href="3-tidy.html"><i class="fa fa-check"></i><b>3</b> Tidy data</a><ul>
<li class="chapter" data-level="3.1" data-path="3-tidy.html"><a href="3-tidy.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.2" data-path="3-tidy.html"><a href="3-tidy.html#the-nycflights13-datasets"><i class="fa fa-check"></i><b>3.2</b> The <code>nycflights13</code> datasets</a></li>
<li class="chapter" data-level="3.3" data-path="3-tidy.html"><a href="3-tidy.html#how-is-flights-tidy"><i class="fa fa-check"></i><b>3.3</b> How is <code>flights</code> tidy?</a></li>
<li class="chapter" data-level="3.4" data-path="3-tidy.html"><a href="3-tidy.html#normal-forms-of-data"><i class="fa fa-check"></i><b>3.4</b> Normal forms of data</a></li>
<li class="chapter" data-level="3.5" data-path="3-tidy.html"><a href="3-tidy.html#whats-to-come"><i class="fa fa-check"></i><b>3.5</b> What’s to come?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-viz.html"><a href="4-viz.html"><i class="fa fa-check"></i><b>4</b> Visualizing Data</a><ul>
<li class="chapter" data-level="4.1" data-path="4-viz.html"><a href="4-viz.html#five-named-graphs---the-fng"><i class="fa fa-check"></i><b>4.1</b> Five Named Graphs - The FNG</a></li>
<li class="chapter" data-level="4.2" data-path="4-viz.html"><a href="4-viz.html#histograms"><i class="fa fa-check"></i><b>4.2</b> Histograms</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-viz.html"><a href="4-viz.html#contsum"><i class="fa fa-check"></i><b>4.2.1</b> Continuous data summaries</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-viz.html"><a href="4-viz.html#summary"><i class="fa fa-check"></i><b>4.2.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-viz.html"><a href="4-viz.html#boxplots"><i class="fa fa-check"></i><b>4.3</b> Boxplots</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-viz.html"><a href="4-viz.html#faceting"><i class="fa fa-check"></i><b>4.3.1</b> Faceting</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-viz.html"><a href="4-viz.html#summary-1"><i class="fa fa-check"></i><b>4.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-viz.html"><a href="4-viz.html#barplots"><i class="fa fa-check"></i><b>4.4</b> Barplots</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-viz.html"><a href="4-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>4.4.1</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-viz.html"><a href="4-viz.html#using-barplots-to-compare-two-variables"><i class="fa fa-check"></i><b>4.4.2</b> Using barplots to compare two variables</a></li>
<li class="chapter" data-level="4.4.3" data-path="4-viz.html"><a href="4-viz.html#summary-2"><i class="fa fa-check"></i><b>4.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-viz.html"><a href="4-viz.html#scatter-plots"><i class="fa fa-check"></i><b>4.5</b> Scatter-plots</a><ul>
<li class="chapter" data-level="4.5.1" data-path="4-viz.html"><a href="4-viz.html#jittering"><i class="fa fa-check"></i><b>4.5.1</b> Jittering</a></li>
<li class="chapter" data-level="4.5.2" data-path="4-viz.html"><a href="4-viz.html#setting-transparency"><i class="fa fa-check"></i><b>4.5.2</b> Setting transparency</a></li>
<li class="chapter" data-level="4.5.3" data-path="4-viz.html"><a href="4-viz.html#summary-3"><i class="fa fa-check"></i><b>4.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-viz.html"><a href="4-viz.html#line-graphs"><i class="fa fa-check"></i><b>4.6</b> Line-graphs</a><ul>
<li class="chapter" data-level="4.6.1" data-path="4-viz.html"><a href="4-viz.html#summary-4"><i class="fa fa-check"></i><b>4.6.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="4-viz.html"><a href="4-viz.html#brief-review-of-the-grammar-of-graphics"><i class="fa fa-check"></i><b>4.7</b> Brief Review of The Grammar of Graphics</a></li>
<li class="chapter" data-level="4.8" data-path="4-viz.html"><a href="4-viz.html#whats-to-come-1"><i class="fa fa-check"></i><b>4.8</b> What’s to come?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-manip.html"><a href="5-manip.html"><i class="fa fa-check"></i><b>5</b> Manipulating Data</a><ul>
<li class="chapter" data-level="5.1" data-path="5-manip.html"><a href="5-manip.html#five-main-verbs---the-fmv"><i class="fa fa-check"></i><b>5.1</b> Five Main Verbs - The FMV</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-manip.html"><a href="5-manip.html#select-variables-using-select"><i class="fa fa-check"></i><b>5.1.1</b> Select variables using <code>select</code></a></li>
<li class="chapter" data-level="5.1.2" data-path="5-manip.html"><a href="5-manip.html#filter-observations-using-filter"><i class="fa fa-check"></i><b>5.1.2</b> Filter observations using <code id="filter">filter</code></a></li>
<li class="chapter" data-level="5.1.3" data-path="5-manip.html"><a href="5-manip.html#summarize-variables-using-summarize"><i class="fa fa-check"></i><b>5.1.3</b> Summarize variables using <code>summarize</code></a></li>
<li class="chapter" data-level="5.1.4" data-path="5-manip.html"><a href="5-manip.html#create-new-variableschange-old-variables-using-mutate"><i class="fa fa-check"></i><b>5.1.4</b> Create new variables/change old variables using <code>mutate</code></a></li>
<li class="chapter" data-level="5.1.5" data-path="5-manip.html"><a href="5-manip.html#reorder-the-data-frame-using-arrange"><i class="fa fa-check"></i><b>5.1.5</b> Reorder the data frame using <code id="arrange">arrange</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-manip.html"><a href="5-manip.html#the-pipe"><i class="fa fa-check"></i><b>5.2</b> The pipe <code>%&gt;%</code></a></li>
<li class="chapter" data-level="5.3" data-path="5-manip.html"><a href="5-manip.html#joiningmerging-data-frames"><i class="fa fa-check"></i><b>5.3</b> Joining/merging data frames</a></li>
<li class="chapter" data-level="5.4" data-path="5-manip.html"><a href="5-manip.html#whats-to-come-2"><i class="fa fa-check"></i><b>5.4</b> What’s to come?</a></li>
</ul></li>
<li class="part"><span><b>Inference</b></span></li>
<li class="chapter" data-level="6" data-path="6-infer-basics.html"><a href="6-infer-basics.html"><i class="fa fa-check"></i><b>6</b> Inference Basics</a><ul>
<li class="chapter" data-level="6.1" data-path="6-infer-basics.html"><a href="6-infer-basics.html#random-sampling"><i class="fa fa-check"></i><b>6.1</b> Random sampling</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-infer-basics.html"><a href="6-infer-basics.html#tasting-soup"><i class="fa fa-check"></i><b>6.1.1</b> Tasting soup</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-infer-basics.html"><a href="6-infer-basics.html#common-terms"><i class="fa fa-check"></i><b>6.1.2</b> Common terms</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-infer-basics.html"><a href="6-infer-basics.html#simulation"><i class="fa fa-check"></i><b>6.2</b> Simulation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-infer-basics.html"><a href="6-infer-basics.html#the-p-value"><i class="fa fa-check"></i><b>6.2.1</b> The p-value</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-infer-basics.html"><a href="6-infer-basics.html#bootstrapping"><i class="fa fa-check"></i><b>6.3</b> Bootstrapping</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-infer-basics.html"><a href="6-infer-basics.html#review-of-bootstrapping"><i class="fa fa-check"></i><b>6.3.1</b> Review of Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-infer-basics.html"><a href="6-infer-basics.html#whats-to-come-3"><i class="fa fa-check"></i><b>6.4</b> What’s to come?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-hypo.html"><a href="7-hypo.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="7.1" data-path="7-hypo.html"><a href="7-hypo.html#trial"><i class="fa fa-check"></i><b>7.1</b> Criminal trial analogy</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-hypo.html"><a href="7-hypo.html#two-possible-conclusions"><i class="fa fa-check"></i><b>7.1.1</b> Two possible conclusions</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-hypo.html"><a href="7-hypo.html#basic-logic-of-hypothesis-testing"><i class="fa fa-check"></i><b>7.1.2</b> Basic Logic of Hypothesis Testing</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-hypo.html"><a href="7-hypo.html#statistical-significance"><i class="fa fa-check"></i><b>7.1.3</b> Statistical Significance</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-hypo.html"><a href="7-hypo.html#randomization"><i class="fa fa-check"></i><b>7.2</b> Randomization</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-hypo.html"><a href="7-hypo.html#comparing-action-and-romance-movies"><i class="fa fa-check"></i><b>7.2.1</b> Comparing Action and Romance Movies</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-hypo.html"><a href="7-hypo.html#sampling---randomization"><i class="fa fa-check"></i><b>7.2.2</b> Sampling -&gt; Randomization</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-hypo.html"><a href="7-hypo.html#summary-5"><i class="fa fa-check"></i><b>7.2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-hypo.html"><a href="7-hypo.html#whats-to-come-4"><i class="fa fa-check"></i><b>7.3</b> What’s to come?</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-ci.html"><a href="8-ci.html"><i class="fa fa-check"></i><b>8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="8.1" data-path="8-ci.html"><a href="8-ci.html#relation-to-hypothesis-testing"><i class="fa fa-check"></i><b>8.1</b> Relation to hypothesis testing</a></li>
<li class="chapter" data-level="8.2" data-path="8-ci.html"><a href="8-ci.html#effect-size"><i class="fa fa-check"></i><b>8.2</b> Effect size</a></li>
<li class="chapter" data-level="8.3" data-path="8-ci.html"><a href="8-ci.html#whats-to-come-5"><i class="fa fa-check"></i><b>8.3</b> What’s to come?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-regress.html"><a href="9-regress.html"><i class="fa fa-check"></i><b>9</b> Simple and Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="9-regress.html"><a href="9-regress.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>9.1</b> Correlation is not causation</a></li>
<li class="chapter" data-level="9.2" data-path="9-regress.html"><a href="9-regress.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="9.3" data-path="9-regress.html"><a href="9-regress.html#mlr"><i class="fa fa-check"></i><b>9.3</b> Multiple linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="9-regress.html"><a href="9-regress.html#types-of-predictors"><i class="fa fa-check"></i><b>9.4</b> Types of predictors</a></li>
<li class="chapter" data-level="9.5" data-path="9-regress.html"><a href="9-regress.html#advanced-topics"><i class="fa fa-check"></i><b>9.5</b> Advanced topics</a></li>
<li class="chapter" data-level="9.6" data-path="9-regress.html"><a href="9-regress.html#whats-to-come-6"><i class="fa fa-check"></i><b>9.6</b> What’s to come?</a></li>
</ul></li>
<li class="part"><span><b>Conclusion</b></span></li>
<li class="chapter" data-level="10" data-path="10-conclusion.html"><a href="10-conclusion.html"><i class="fa fa-check"></i><b>10</b> Concluding Remarks</a></li>
<li class="part"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="11" data-path="11-appendix1.html"><a href="11-appendix1.html"><i class="fa fa-check"></i><b>11</b> Appendix A: Intermediate R</a><ul>
<li class="chapter" data-level="11.1" data-path="11-appendix1.html"><a href="11-appendix1.html#sorted-barplots"><i class="fa fa-check"></i><b>11.1</b> Sorted barplots</a></li>
<li class="chapter" data-level="11.2" data-path="11-appendix1.html"><a href="11-appendix1.html#interactive-graphics"><i class="fa fa-check"></i><b>11.2</b> Interactive graphics</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-appendix1.html"><a href="11-appendix1.html#interactive-line-graphs"><i class="fa fa-check"></i><b>11.2.1</b> Interactive line-graphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-appendix2.html"><a href="12-appendix2.html"><i class="fa fa-check"></i><b>12</b> Appendix B: Statistical Basics</a><ul>
<li class="chapter" data-level="12.1" data-path="12-appendix2.html"><a href="12-appendix2.html#basic-statistical-terms"><i class="fa fa-check"></i><b>12.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-appendix2.html"><a href="12-appendix2.html#mean"><i class="fa fa-check"></i><b>12.1.1</b> Mean</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-appendix2.html"><a href="12-appendix2.html#median"><i class="fa fa-check"></i><b>12.1.2</b> Median</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-appendix2.html"><a href="12-appendix2.html#standard-deviation"><i class="fa fa-check"></i><b>12.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-appendix2.html"><a href="12-appendix2.html#five-number-summary"><i class="fa fa-check"></i><b>12.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-appendix2.html"><a href="12-appendix2.html#distribution"><i class="fa fa-check"></i><b>12.1.5</b> Distribution</a></li>
<li class="chapter" data-level="12.1.6" data-path="12-appendix2.html"><a href="12-appendix2.html#outliers"><i class="fa fa-check"></i><b>12.1.6</b> Outliers</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-references.html"><a href="13-references.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A MODERN DIVE into Data with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="infer-basics" class="section level1">
<h1><span class="header-section-number">6</span> Inference Basics</h1>
<p>In this chapter we will introduce new concepts that will serve as the basis for the remainder of the text: <strong>sampling</strong>, <strong>bootstrapping</strong> and <strong>resampling</strong>. We will see that the tools that you learned in the Data Exploration part of this book (tidy data, data manipulation, and data visualization) will also play an important role here. As mentioned before, the concepts all build into a culmination allowing you to create better stories with data.</p>
<p>We begin with some helpful definitions that will help us better understand why statistical inference exists and why it is needed. We will then progress with a famous example from statistics lore and then introduce the second of our main data sets (in addition to the <code>nycflights13</code> data you’ve been working with) about movie ratings from IMDB.com. We will see how we can use samples from this data set to infer more general conclusions about all of the movies (in the population).</p>
<div id="random-sampling" class="section level2">
<h2><span class="header-section-number">6.1</span> Random sampling</h2>
<p>Whenever you hear the phrases “random sampling” or just “sampling” (with regards to statistics), you should think about tasting soup. This likely sounds a little bonkers. Let’s dig in to why tasting soup is such an excellent analogy to random sampling.</p>
<div id="tasting-soup" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Tasting soup</h3>
<div class="figure" style="text-align: center"><span id="fig:soupimg"></span>
<img src="images/soup.jpg" alt="A bowl of Indian chicken and vegetable soup" width="\textwidth" />
<p class="caption">
Figure 6.1: A bowl of Indian chicken and vegetable soup
</p>
</div>
<p>Imagine that you have invited a group of friends over to try a new recipe for soup that you’ve never made before. As in the image above downloaded from <a href="http://readthespirit.wpengine.netdna-cdn.com/feed-the-spirit/wp-content/uploads/sites/19/2015/02/Chicken-soup-Indian-by-Fifth-Floor-Kitchen.jpg">here</a>, you’d like to make a bowl of Indian chicken soup with lots of different kinds of vegetables included.</p>
<p>You’ve carefully followed along with the recipe but you are concerned that you don’t have a lot of experience making Indian-style foods. It is coming near the end of the prescribed time to cook given in the recipe. You begin to wonder:</p>
<ul>
<li>“Did I add too much curry spice?”</li>
<li>“Are the carrots cooked enough?”<br />
</li>
<li>“Does this actually taste good?”</li>
</ul>
<p>How can we answer these questions? Does it matter where we take a bite of soup from? Is there anything we should do to the soup before we taste? Is one taste enough?</p>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.1)</strong> Explain in your own words how tasting soup relates to the concepts of sampling covered here.</p>
<p><strong>(LC6.2)</strong> Describe a different scenario (not food or drink related) that is analogous to sampling concepts covered here.</p>
<hr />
</div>
<div id="common-terms" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Common terms</h3>
<p>The process of sampling brings with it many common terms that we define now. As you read over these definitions, think about how they each apply to the tasting soup example above.</p>
<hr />
<p><strong>Definition: population</strong></p>
<p>The <em>population</em> is the (usually) large pool of observational units that we are interested in.</p>
<p><strong>Definition: sample</strong></p>
<p>A <em>sample</em> is a smaller collection of observational units that is selected from the population.</p>
<p><strong>Definition: sampling</strong></p>
<p><em>Sampling</em> refers to the process of selecting observations from a population. There are both random and non-random ways this can be done.</p>
<p><strong>Definition: representative sample</strong></p>
<p>A sample is said be a <em>representative sample</em> if the characteristics of observational units selected are a good approximation of the characteristics from the original population.</p>
<p><strong>Definition: bias</strong></p>
<p><em>Bias</em> corresponds to a favoring of one group in a population over another group.</p>
<p><strong>Definition: generalizability</strong></p>
<p><em>Generalizability</em> refers to the largest group in which it makes sense to make inferences about from the sample collected. This is directly related to how the sample was selected.</p>
<p><strong>Definition: parameter</strong></p>
<p>A <em>parameter</em> is a calculation based on one or more variables measured in the population. Parameters are almost always denoted symbolically using Greek letters such as <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\pi\)</span>, <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\rho\)</span>, and <span class="math inline">\(\beta\)</span>.</p>
<p><strong>Definition: statistic</strong></p>
<p>A <em>statistic</em> is a calculated based on one or more variables measured in the sample. Parameters are usually denoted by lower case Arabic letters with other symbols added sometimes. These include <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(\hat{p}\)</span>, <span class="math inline">\(s\)</span>, <span class="math inline">\(p\)</span>, and <span class="math inline">\(b\)</span>.</p>
<hr />
<p>Let’s explore these terms for our tasting soup example:</p>
<p><em>Population</em> - the entire container of soup that we have cooked.</p>
<p><em>Sample</em> - any smaller portion of soup collected that isn’t the whole container of soup. We could say that each spoonful of soup represents one sample.</p>
<p><em>Sampling</em> - the process of selecting spoonfuls from the container of soup</p>
<p><em>Representative sample</em> - A sample we select will only be representative if it tastes like what the soup tastes like in general. If we only select a carrot in our spoonful, we might not have a representative sample.</p>
<p><em>Bias</em> - As we noted with the carrot selection example above, we may select a sample that is not representative. If you watch chefs cook or if you frequently cook, you’ll be sure to stir the soup before you taste it.</p>
<p><em>Generalizability</em> - If we stir our soup before we taste a spoonful (and if we make sure we don’t just pick our favorite item in the soup), results from our sample can be generalized (by and large) to the larger pot of soup. When we say “Yum! This is good!” after a couple spoonfuls, we can be pretty confident that each bowl of soup for our friends will taste good too.</p>
<p><em>Parameter</em> - An example here is could be the proportion of curry entered into the entire pot of soup. A measurement of how salty the pot of soup is on average is also a parameter. How crunchy, on average, the carrots are in the pot of soup is one more example.</p>
<p><em>Statistic</em> - To convert a parameter to a statistic, you need only to think about the same measurement on a spoonful:</p>
<ul>
<li>The proportion of curry to non-curry in a spoonful of soup</li>
<li>How salty the spoonful of soup is that we collected as our sample</li>
<li>How crunchy the carrots are in our spoonful of soup</li>
</ul>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.3)</strong> Why isn’t our population all bowls of soup? All bowls of Indian chicken soup?</p>
<p><strong>(LC6.4)</strong> Describe a way in which we could select a sample of flights from <code>nycflights13</code> that is not representative.</p>
<p><strong>(LC6.5)</strong> If we treat all of the flights in <code>nycflights13</code> as the population, give examples of three <em>parameters</em> we could calculate.</p>
<p><strong>(LC6.6)</strong> If we treat all of the flights in <code>nycflights13</code> as the population, give examples of three <em>statistics</em> we could calculate.</p>
<p><strong>(LC6.7)</strong> What biases might we see if we only select flights to Boston when we are interested in looking at mean flight delays from NYC?</p>
<hr />
</div>
</div>
<div id="simulation" class="section level2">
<h2><span class="header-section-number">6.2</span> Simulation</h2>
<p>What follows is taken from a book entitled <em>The Lady Tasting Tea</em> <span class="citation">(Salsburg <a href="#ref-salsburg2001">2001</a>)</span>:</p>
<blockquote>
<p>It was a summer afternoon in Cambridge, England, in the late 1920s. A group of university dons, their wives, and some guests were sitting around an outdoor table for afternoon tea. One of the women was insisting that tea tasted different depending upon whether the tea was poured into the milk or whether the milk was poured into the tea. The scientific minds among the men scoffed at this as sheer nonsense. What could be the difference? They could not conceive of any difference in the chemistry of the mixtures that could exist. A thin, short man, with thick glasses and a Vandyke beard beginning to turn gray, pounced on the problem. “Let us test the proposition,” he said excitedly. He began to outline an experiment in which the lady who insisted there was a difference would be presented with a sequence of cups of tea, in some of which the milk had been poured into the tea and in others of which the tea had been poured into the milk…</p>
</blockquote>
<blockquote>
<p>So it was that sunny summer afternoon in Cambridge. The lady might or might not have been correct about the tea infusion. The fun would be in finding a way to determine if she was right, and, under the direction of the man with the Vandyke beard, they began to discuss how they might make that determination.</p>
</blockquote>
<blockquote>
<p>Enthusiastically, many of them joined with him in setting up the experiment. Within a few minutes, they were pouring different patterns of infusion in a place where the lady could not see which cup was which. Then, with an air of finality, the man with the Vandyke beard presented her with her first cup. She sipped for a minute and declared that it was one where the milk had been poured into the tea. He noted her response without comment and presented her with the second cup…</p>
</blockquote>
<blockquote>
<p>The man with the Vandyke beard was Ronald Aylmer Fisher, who was in his late thirties at the time. He would later be knighted Sir Ronald Fisher. In 1935, he wrote a book entitled <em>The Design of Experiments</em>, and he described the experiment of the lady tasting tea in the second chapter of that book. In his book, Fisher discusses the lady and her belief as a hypothetical problem. He considers the various ways in which an experiment might be designed to determine if she could tell the difference. The problem in designing the experiment is that, if she is given a single cup of tea, she has a 50 percent chance of guessing correctly which infusion was used, even if she cannot tell the difference. If she is given two cups of tea, she still might guess correctly. In fact, if she knew that the two cups of tea were each made with a different infusion, one guess could be completely right (or completely wrong).</p>
</blockquote>
<blockquote>
<p>Similarly, even if she could tell the difference, there is some chance that she might have made a mistake, that one of the cups was not mixed as well or that the infusion was made when the tea was not hot enough. She might be presented with a series of ten cups and correctly identify only nine of them, even if she could tell the difference.</p>
</blockquote>
<blockquote>
<p>In his book, Fisher discusses the various possible outcomes of such an experiment. He describes how to decide how many cups should be presented and in what order and how much to tell the lady about the order of presentations. He works out the probabilities of different outcomes, depending upon whether the lady is or is not correct. Nowhere in this discussion does he indicate that such an experiment was ever run. Nor does he describe the outcome of an actual experiment.</p>
</blockquote>
<p>It’s amazing that there is no actual evidence that such an event actually took place. This problem is a great introduction into inference though and we can proceed by testing to see how likely it is for a person to guess correctly, say, 9 out of 10 times assuming that that person is just guessing. In other words, is the person just lucky or do we have reason to suspect that they can actually detect whether milk was put in first or not?</p>
<p>We need to think about this problem from the standpoint of hypothesis testing. First, we’ll need to identify some important parts of a hypothesis test before we proceed with the analysis.</p>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.8)</strong> What does “by chance” mean in this context?</p>
<p><strong>(LC6.9)</strong> What is our observed statistic?</p>
<p><strong>(LC6.10)</strong> What is this statistic trying to estimate?</p>
<p><strong>(LC6.11)</strong> How could we test to see whether the person is just guessing or if they have some special talent of identifying milk before tea or vice-versa?</p>
<hr />
<!--
- Q: What does "by chance" mean in this context?
    A:  We are assuming that the person is just guessing.  This corresponds to them being equally likely to guess whether or not milk was entered first, i.e., the probability of ``success" is 0.5.
- Q:  What is our observed statistic?
    A:  It isn't ever given just how many times out of 10 trials the supposed lady guessed correctly.  We assumed above that the person got 9 out of 10 correct.  This corresponds to our sample statistic of $\hat{p} = 0.9$.
- Q:  What is the statistic trying to estimate?
  A:  The statistic provides one guess as to a value of the parameter.  We denote this parameter by the Greek letter $\pi$ and here it corresponds to the long-run probability that the person will correctly guess whether milk or tea was added first, if the experiment was repeated many times.
- Q:  How do we test to see whether the person is just guessing or if they have some special talent of identifying milk before tea or vice versa?
    A:  Let's begin with an experiment.  I will flip a coin 10 times.  Your job is to try to predict the sequence of my 10 flips.  Write down 10 H's and T's corresponding to your predictions.  We will compare your guesses with my actual flips and then we will note how many correct guesses each of you have. 

-->
<p>Let’s begin with an experiment. I will flip a coin 10 times. Your job is to try to predict the sequence of my 10 flips. Write down 10 H’s and T’s corresponding to your predictions. We could compare your guesses with my actual flips and then we will note how many correct guesses you have.</p>
<p>You may be asking yourself how this models a way to test whether the person was just guessing or not. All we are trying to do is see how likely it is to have 9 matches out of 10 if the person was truly guessing. When we say “truly guessing” we are assuming that we have a 50/50 chance of guessing correctly. This can be modeled using a coin flip and then seeing whether we guessed correctly for each of the coin flips. If we guessed correctly, we can think of that as a “success.”</p>
<p>We often don’t have time to do the physical flipping over and over again and we’d like to be able to do more than just 20 different simulations or so. Luckily, we can use R to simulate this process many times. The <code>mosaic</code> package includes a function called <code>rflip()</code>, which can be used to flip one coin. Well, not exactly. It uses pseudo-random number generation to “flip” a virtual coin. In order for us all to get the same results here, we can set the seed of the pseudo-random number generator. Let’s see an example of this: (Remember to load the <code>mosaic</code> package!)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)
<span class="kw">set.seed</span>(<span class="dv">2016</span>)
<span class="kw">do</span>(<span class="dv">1</span>) *<span class="st"> </span><span class="kw">rflip</span>(<span class="dv">1</span>)</code></pre></div>
<pre><code>##   n heads tails prop
## 1 1     0     1    0</code></pre>
<p>This shows us the proportion of “successes” in one flip of a coin. The <code>do</code> function in the <code>mosaic</code> package will be useful and you can begin to understand what it does with another example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">do</span>(<span class="dv">13</span>) *<span class="st"> </span><span class="kw">rflip</span>(<span class="dv">10</span>)</code></pre></div>
<pre><code>##     n heads tails prop
## 1  10     4     6  0.4
## 2  10     7     3  0.7
## 3  10     3     7  0.3
## 4  10     3     7  0.3
## 5  10     3     7  0.3
## 6  10     6     4  0.6
## 7  10     2     8  0.2
## 8  10     6     4  0.6
## 9  10     4     6  0.4
## 10 10     4     6  0.4
## 11 10     6     4  0.6
## 12 10     7     3  0.7
## 13 10     2     8  0.2</code></pre>
<p>We’ve now done a simulation of what actually happened when you flipped a coin ten times. We have 13 different simulations of flipping a coin 10 times. Note here that <code>heads</code> now corresponds to the number of correct guesses and <code>tails</code> corresponds to the number of incorrect guesses. (This can be tricky to understand at first since we’ve done a switch on what the meaning of “heads” and ``tails&quot; are.)</p>
<p>If you look at the output above for our simulation of 13 student guesses, we can begin to get a sense for what an “expected” sample proportion of successes may be. Around five out of 10 seems to be the most likely value. What does this say about our assumed <span class="math inline">\(\hat{p}\)</span> of 9/10? To better answer this question, we can simulate 10,000 student guesses and then look at the distribution of the simulated sample proportion of successes, also known as the <strong>null distribution</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tibble)
simGuesses &lt;-<span class="st"> </span><span class="kw">do</span>(<span class="dv">10000</span>) *<span class="st"> </span><span class="kw">rflip</span>(<span class="dv">10</span>)
simGuesses &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(simGuesses)
simGuesses %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(heads) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>())</code></pre></div>
<pre><code>## # A tibble: 11 × 2
##    heads count
##    &lt;dbl&gt; &lt;int&gt;
## 1      0     7
## 2      1    81
## 3      2   424
## 4      3  1084
## 5      4  2075
## 6      5  2479
## 7      6  2117
## 8      7  1157
## 9      8   461
## 10     9   105
## 11    10    10</code></pre>
<p><strong>Note:</strong> Here <code>as_tibble</code> converts data frames to tibbles. This is also why the <code>library(tibble)</code> command is needed. The conversion to <code>tibble</code> format is mostly done for allowing for nice printing of large data sets when we mention the name of a data frame object in a chunk by itself. (The data sets in <code>nycflights13</code> come as tibbles by default.) You can read more about tibbles in Chapter 10 of Hadley and Garrett’s book <span class="citation">(Grolemund and Wickham <a href="#ref-rds2016">2016</a>)</span>.</p>
<p>We can see here that we have created a count of how many of each of the 10,000 sets of 10 flips resulted in 0, 1, 2, …, up to 10 heads. Note the use of the <code>group_by</code> and <code>summarize</code> functions from Chapter <a href="5-manip.html#manip">5</a> here.</p>
<p>In addition, we can plot the distribution of these simulated <code>heads</code> using the ideas from Chapter <a href="4-viz.html#viz">4</a>. <code>heads</code> is a quantitative variable. Think about which type of plot is most appropriate here before reading further.</p>
<p>We already have an idea as to an appropriate plot by the data summarization that we did in the chunk above. We’d like to see how many heads occurred in the 10,000 sets of 10 flips. In other words, we’d like to see how frequently 9 or more heads occurred in the 10 flips:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
simGuesses %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> heads)) +
<span class="st">  </span><span class="kw">geom_bar</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-75"></span>
<img src="ismay_files/figure-html/unnamed-chunk-75-1.png" alt="Barplot of number of heads in simulation - needs tweaking" width="\textwidth" />
<p class="caption">
Figure 6.2: Barplot of number of heads in simulation - needs tweaking
</p>
</div>
<p>This horizontal axis labels are a little confusing here. What does 2.5 or 7.5 heads mean? In <code>simGuesses</code>, <code>heads</code> is a <code>numerical</code> variable. Thus, <code>ggplot</code> is expecting the values to be on a continuous scale. We can switch the scale to be discrete by invoking the <code>factor</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
simGuesses %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(heads))) +
<span class="st">  </span><span class="kw">geom_bar</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-76"></span>
<img src="ismay_files/figure-html/unnamed-chunk-76-1.png" alt="Barplot of number of heads in simulation" width="\textwidth" />
<p class="caption">
Figure 6.3: Barplot of number of heads in simulation
</p>
</div>
<p>You’ll frequently need to make this conversion to <code>factor</code> when making a barplot with quantitative variables. Remember from “Getting Used to R, RStudio, and R Markdown” <span class="citation">(Ismay <a href="#ref-usedtor2016">2016</a>)</span>, that a <code>factor</code> variable is useful when there is a natural ordering to the variable. Our <code>heads</code> variable has a natural ordering: 0, 1, 2, …, 10.</p>
<div id="the-p-value" class="section level3">
<h3><span class="header-section-number">6.2.1</span> The p-value</h3>
<hr />
<p><strong>Definition: <span class="math inline">\(p\)</span>-value</strong>:</p>
<p>The  is the probability of observing a sample statistic as extreme or more extreme than what was observed, assuming that the null hypothesis of a by chance operation is true.</p>
<hr />
<p>This definition may be a little intimidating the first time you read it, but it’s important to come back to this “The Lady Tasting Tea” problem whenever you encounter <span class="math inline">\(p\)</span>-values as you begin to learn about the concept. Here the <span class="math inline">\(p\)</span>-value corresponds to how many times in our <strong>null distribution</strong> of <code>heads</code> 9 or more heads occurred.</p>
<p>We can use another neat feature of R to calculate the <span class="math inline">\(p\)</span>-value for this problem. Note that “more extreme” in this case corresponds to looking at values of 9 or greater since our alternative hypothesis invokes a right-tail test corresponding to a “greater than” hypothesis of <span class="math inline">\(H_a: \pi &gt; 0.5\)</span>. In other words, we are looking to see how likely it is for the lady to pick 9 or more correct instead of 9 or less correct. We’d like to go in the right direction.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pvalue_tea &lt;-<span class="st"> </span>simGuesses %&gt;%
<span class="st">  </span><span class="kw">filter</span>(heads &gt;=<span class="st"> </span><span class="dv">9</span>) %&gt;%
<span class="st">  </span><span class="kw">nrow</span>() /<span class="st"> </span><span class="kw">nrow</span>(simGuesses)</code></pre></div>
<p>Let’s walk through each step of this calculation:</p>
<ol style="list-style-type: decimal">
<li><p>First, <code>pvalue_tea</code> will be the name of our calculated <span class="math inline">\(p\)</span>-value and the assignment operator <code>&lt;-</code> directs us to this naming.</p></li>
<li><p>We are working with the <code>simGuesses</code> data frame here so that comes immediately before the pipe operator.</p></li>
<li><p>We would like to only focus on the rows in our <code>simGuesses</code> data frame that have <code>heads</code> values of 9 or 10. This represents simulated statistics “as extreme or more extreme” than what we observed (9 correct guesses out of 10). Let’s get a glimpse of what we have up to this point:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simGuesses %&gt;%<span class="st"> </span><span class="kw">tbl_df</span>() %&gt;%
<span class="st">  </span><span class="kw">filter</span>(heads &gt;=<span class="st"> </span><span class="dv">9</span>)    </code></pre></div>
<pre><code>## # A tibble: 115 × 4
##        n heads tails  prop
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     10     9     1   0.9
## 2     10     9     1   0.9
## 3     10     9     1   0.9
## 4     10     9     1   0.9
## 5     10     9     1   0.9
## 6     10     9     1   0.9
## 7     10    10     0   1.0
## 8     10     9     1   0.9
## 9     10     9     1   0.9
## 10    10     9     1   0.9
## # ... with 105 more rows</code></pre></li>
<li><p>Now that we have changed the focus to only those rows that have number of heads out of 10 flips corresponding to 9 or more, we count how many of those there are. The function <code>nrow</code> gives how many entries are in this filtered data frame and lastly we calculate the proportion that are at least as extreme as our observed value of 9 by dividing by the number of total simulations (10,000).</p></li>
</ol>
<p>We can see that the observed statistic of 9 correct guesses is not a likely outcome assuming the null hypothesis is true. Only around 1% of the outcomes in our 10,000 simulations fall at or above 9 successes. We have evidence supporting the conclusion that the person is actually better than just guessing at random at determining whether milk has been added first or not. To better visualize this we can also make use of pink shading on the histogram corresponding to the <span class="math inline">\(p\)</span>-value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
simGuesses %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(heads), <span class="dt">fill =</span> (heads &gt;=<span class="st"> </span><span class="dv">9</span>))) +
<span class="st">  </span><span class="kw">geom_bar</span>() +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;heads&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-79"></span>
<img src="ismay_files/figure-html/unnamed-chunk-79-1.png" alt="Barplot of heads with p-value highlighted" width="\textwidth" />
<p class="caption">
Figure 6.4: Barplot of heads with p-value highlighted
</p>
</div>
<p>This helps us better see just how few of the values of <code>heads</code> are at our observed value or more extreme.</p>
<p>We’ll see in Chapters <a href="7-hypo.html#hypo">7</a> and <a href="8-ci.html#ci">8</a> that this idea of a <span class="math inline">\(p\)</span>-value can be extended to the more traditional methods using normal and <span class="math inline">\(t\)</span> distributions in the traditional way that introductory statistics has been presented. These traditional methods were used because statisticians haven’t always been able to do 10,000 simulations on the computer within seconds. We’ll elaborate on this more in these later chapters.</p>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.12)</strong> What is meant by “pseudo-random number generation?”</p>
<p><strong>(LC6.13)</strong> How can simulation be used to help us address the question of whether or not an observed result is statistically significant?</p>
<p><strong>(LC6.14)</strong> In Chapter <a href="4-viz.html#viz">4</a>, we noted that barplots should be used when creating a plot of categorical variables. Why are we using barplots to make a plot of a numerical variable <code>heads</code> in this chapter?</p>
<hr />
</div>
</div>
<div id="bootstrapping" class="section level2">
<h2><span class="header-section-number">6.3</span> Bootstrapping</h2>
<p>Just as we did in the previous section when making hypotheses about a population proportion with which we would like to test which one is more plausible, we can also use simulation to infer conclusions about a population quantitative statistic such as the mean. In this case, we will focus on constructing confidence intervals to produce plausible values for a population mean. (We can do a similar analysis for a population median or other summary measure as well.)</p>
<p>Traditionally, the way to construct confidence intervals for a mean is to assume a normal distribution for the population or to invoke the Central Limit Theorem and get, what often appears to be magic, results. These methods are often not intuitive, especially for those that lack a strong mathematical background. They also come with their fair share of assumptions and often turn Statistics, a field that is full of tons of useful applications to many different fields and disciplines, into a robotic procedural-based topic. It doesn’t have to be that way!</p>
<p>In this section, we will introduce the concept of <strong>bootstrapping</strong>. It will be a useful tool that will allow us to estimate the variability of our statistic from sample to sample. One neat feature of bootstrapping is that it enables us to approximate the sampling distribution and estimate the distribution’s standard deviation using ONLY the information in the one selected (original) sample.</p>
<p>It sounds just as plagued with the magical type qualities of traditional theory-based inference on initial glance but we will see that it provides an intuitive and useful way to make inferences, especially when the samples are of medium to large size.</p>
<!--We will begin by investigating an example on the selling prices of used Ford Mustang cars taken from the textbook {\it Statistics:  UnLOCKing the Power of Data} by Lock, Lock, Lock, Lock, and Lock.  (That isn't me hitting Copy+Paste too many times.  Patti and Robin Lock both work in the Mathematics Department at St. Lawrence University and they have three children that are statisticians.  They are often referred to as the Lock5.)
-->
<p>To introduce the concept of bootstrapping, we now introduce the <code>movies</code> data set in the <code>ggplot2movies</code> data frame. We will load this data frame into R in much the same way as we loaded <code>flights</code> and <code>weather</code> from the <code>nycflights13</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2movies)
<span class="kw">data</span>(movies, <span class="dt">package =</span> <span class="st">&quot;ggplot2movies&quot;</span>)</code></pre></div>
<p>Let’s also glance at this data frame using the <code>View</code> function and look at the help documentation for <code>movies</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(movies)
?movies</code></pre></div>
<p>We will explore many other features of this data set in the chapters to come, but here we will be focusing on the <code>rating</code> variable corresponding to the average IMDB user rating.</p>
<p>You may notice that this data set is quite large: 58,788 movies have data collected about them here. This will correspond to our population of ALL movies. Remember from Chapter <a href="6-infer-basics.html#infer-basics">6</a> that our population is rarely known. We use this data set as our population here to show you the power of bootstrapping in estimating population parameters. We’ll see how <strong>confidence intervals</strong> built using the bootstrap distribution do at including our population parameter of interest. Here we can actually calculate these values since our population is known, but remember that in general this isn’t the case.</p>
<p>Let’s take a look at what the distribution of our population <code>ratings</code> looks like. We’ll see that we will use the distribution of our sample(s) as an estimate of this population histogram.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> rating)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">20</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-82"></span>
<img src="ismay_files/figure-html/unnamed-chunk-82-1.png" alt="Population ratings histogram" width="\textwidth" />
<p class="caption">
Figure 6.5: Population ratings histogram
</p>
</div>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.15)</strong> Why was a histogram chosen as the plot to make for the <code>rating</code> variable above?</p>
<p><strong>(LC6.16)</strong> Why does the shape of the <code>rating</code> histogram tell us about how IMDB users rate movies? What stands out about the plot?</p>
<hr />
<p>It’s important to think about what our goal is here. We would like to produce a confidence interval for the population mean <code>rating</code>. We will have to pretend for a moment that we don’t have all 58,788 movies. Let’s say that we only have a random sample of 50 movies from this data set instead. In order to get a random sample, we can use the <code>sample_n</code> function from <code>dplyr</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2016</span>)
movies_sample &lt;-<span class="st"> </span>movies %&gt;%
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">50</span>)</code></pre></div>
<p>The <code>sample_n</code> function has filtered the data frame <code>movies</code> “at random” to choose only 50 rows from the larger <code>movies</code> data frame. We store information on these 50 movies in the <code>movies_sample</code> data frame.</p>
<p>Let’s now explore what the <code>rating</code> variable looks like for these 50 movies:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies_sample %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> rating)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">20</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-84"></span>
<img src="ismay_files/figure-html/unnamed-chunk-84-1.png" alt="Sample ratings histogram" width="\textwidth" />
<p class="caption">
Figure 6.6: Sample ratings histogram
</p>
</div>
<p>Remember that we can think of this histogram as an estimate of our population distribution histogram that we saw above. We are interested in the population mean rating and trying to find a range of plausible values for that value. A good start in guessing the population mean is to use the mean of our sample <code>rating</code> from the <code>movies_sample</code> data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(movies_sample_mean &lt;-<span class="st"> </span>movies_sample %&gt;%<span class="st"> </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating)))</code></pre></div>
<pre><code>## # A tibble: 1 × 1
##    mean
##   &lt;dbl&gt;
## 1 6.034</code></pre>
<p>Note the use of the <code>( )</code> at the beginning and the end of this creation of the <code>movies_sample_mean</code> object. If you’d like to print out your newly created object, you can enclose it in the parentheses as we have here.</p>
<p>This value of 6.034 is just one guess at the population mean. The idea behind <em>bootstrapping</em> is to sample <strong>with replacement</strong> from the original sample to create new <strong>resamples</strong> of the same size as our original sample.</p>
<p>Returning to our example, let’s investigate what one such resample of the <code>movies_sample</code> data set accomplishes. We can create one resample/bootstrap sample by using the <code>resample</code> function in the <code>mosaic</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)
<span class="kw">library</span>(tibble)
boot1 &lt;-<span class="st"> </span><span class="kw">resample</span>(movies_sample, <span class="dt">orig.ids =</span> <span class="ot">TRUE</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(orig.id, <span class="kw">everything</span>()) %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(orig.id)</code></pre></div>
<p>Take a look at this resample/bootstrap:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(boot1)</code></pre></div>
<p>The important thing to note here is the original row numbers from the <code>movies_sample</code> data frame in the far left column called <code>orig.ids</code>. Since we are sampling with replacement, there is a strong likelihood that some of the 50 observational units are going to be selected again.</p>
<p>You may be asking yourself what does this mean and how to this lead us to creating a distribution for the sample mean. Recall that the original sample mean of our data was calculated using the <code>summarize</code> function above.</p>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.17)</strong> What happens if we change the seed to our pseudo-random generation? Try it above when we used <code>sample_n</code> to describe the resulting <code>movies_sample</code>.</p>
<p><strong>(LC6.18)</strong> Why is sampling at random important from the <code>movies</code> data frame? Why don’t we just pick <code>Action</code> movies and do bootstrapping with this <code>Action</code> movies subset?</p>
<p><strong>(LC6.19)</strong> What was the purpose of assuming we didn’t have access to the full <code>movies</code> data set here?</p>
<hr />
<p>Before we had a calculated mean in our original sample of 6.034. Let’s calculate the mean of <code>ratings</code> in our bootstrapped sample:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(movies_boot1_mean &lt;-<span class="st"> </span>boot1 %&gt;%<span class="st"> </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating)))</code></pre></div>
<pre><code>## # A tibble: 1 × 1
##    mean
##   &lt;dbl&gt;
## 1 6.144</code></pre>
<p>More than likely the calculated bootstrap sample mean is different than the original sample mean. This is what I meant earlier when I said that the sample means have some variability. What we are trying to do is replicate many different samples being taken from a larger population. Our best guess at what the population looks like is multiple copies of the sample we collected. We then can sample from that larger “created” population by generating bootstrap samples.</p>
<p>Similar to what we did in the previous section, we can repeat this process using the <code>do</code> function followed by an asterisk. Let’s look at 10 different bootstrap means for <code>ratings</code> from <code>movies_sample</code>. Note the use of the <code>resample</code> function here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">do</span>(<span class="dv">10</span>) *<span class="st"> </span><span class="kw">summarize</span>(<span class="kw">resample</span>(movies_sample), <span class="dt">mean =</span> <span class="kw">mean</span>(rating))</code></pre></div>
<pre><code>##     mean
## 1  6.020
## 2  6.668
## 3  5.996
## 4  6.056
## 5  6.168
## 6  6.360
## 7  5.702
## 8  6.218
## 9  6.252
## 10 5.904</code></pre>
<p>You should see some variability begin to tease its way out here. Many of the simulated means will be close to our original sample mean but many will stray pretty far away. This occurs because outliers may have been selected a couple of times in the resampling or small values were selected more than larger. There are myriad reasons why this might be the case.</p>
<p>So what’s the next step now? Just as we repeated the repetitions thousands of times with the “Lady Tasting Tea” example, we can do a similar thing here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trials &lt;-<span class="st"> </span><span class="kw">do</span>(<span class="dv">10000</span>) *<span class="st"> </span><span class="kw">summarize</span>(<span class="kw">resample</span>(movies_sample), 
                                <span class="dt">mean =</span> <span class="kw">mean</span>(rating))
trials %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mean)) +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-90"></span>
<img src="ismay_files/figure-html/unnamed-chunk-90-1.png" alt="Bootstrapped means histogram" width="\textwidth" />
<p class="caption">
Figure 6.7: Bootstrapped means histogram
</p>
</div>
<p>The shape of this resulting distribution may look familiar to you. It resembles the well-known normal (bell-shaped) curve. We will see in Chapters <a href="7-hypo.html#hypo">7</a> and <a href="8-ci.html#ci">8</a> when we might expect a normal curve to come through as we have here and when we shouldn’t. There will be specific assumptions that need to be checked and we will see that the normal distribution doesn’t always approximate this bootstrapped distribution well. In those case, we should NOT rely on traditional methods.</p>
<p>At this point, we can easily calculate a confidence interval. In fact, we have a couple different options. We will first use the percentiles of the distribution we just created to isolate the middle 95% of values. This will correspond to our 95% confidence interval for the population mean <code>rating</code>, denoted by <span class="math inline">\(\mu\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(ciq_mean_rating &lt;-<span class="st"> </span><span class="kw">confint</span>(trials, <span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">method =</span> <span class="st">&quot;quantile&quot;</span>))</code></pre></div>
<pre><code>##   name   lower upper level     method estimate
## 1 mean 5.50795  6.54  0.95 percentile    6.034</code></pre>
<p>It’s always important at this point to interpret the results of this confidence interval calculation. In this context, we can say something like the following:</p>
<blockquote>
<p>Based on the sample data and bootstrapping techniques, we can be 95% confident that the true mean rating of ALL IMDB ratings is between 5.50795 and 6.54.</p>
</blockquote>
<p>This statement may seem a little confusing to you. Remember that we are pretending like we don’t know what the mean IMDB rating for ALL movies is. Our population here is all of the movies listed in the <code>movies</code> data frame from <code>ggplot2movies</code>. So does our bootstrapped confidence interval here contain the actual mean value?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summarize</span>(movies, <span class="dt">mean =</span> <span class="kw">mean</span>(rating))</code></pre></div>
<pre><code>## # A tibble: 1 × 1
##      mean
##     &lt;dbl&gt;
## 1 5.93285</code></pre>
<p>We see here that the population mean does fall in our range of plausible values generated from the bootstrapped samples.</p>
<p>We can also get an idea of how the theory-based inference techniques would have approximated this confidence interval by using the formula <span class="math display">\[\bar{x} \pm (2 * SE),\]</span> where <span class="math inline">\(\bar{x}\)</span> is our original sample mean and <span class="math inline">\(SE\)</span> stands for <strong>standard error</strong> and corresponds to the standard deviation of the bootstrap distribution. The value of 2 here corresponds to it being a 95% confidence interval. This formula assumes that the bootstrap distribution is symmetric. This is often the case with bootstrap distributions, especially those in which the original distribution of the sample is not highly skewed.</p>
<p>To compute this type of confidence interval, we only need to make a slight modification to the <code>confint</code> function seen above. (The expression after the <span class="math inline">\(\pm\)</span> sign is known as the <strong>margin of error</strong>.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(cise_mean_rating &lt;-<span class="st"> </span><span class="kw">confint</span>(trials, <span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">method =</span> <span class="st">&quot;stderr&quot;</span>))</code></pre></div>
<pre><code>##   name    lower    upper level method estimate margin.of.error
## 1 mean 5.516196 6.551379  0.95 stderr    6.034       0.5175914</code></pre>
<blockquote>
<p>Based on the sample data and bootstrapping techniques, we can be 95% confident that the true mean rating of ALL IMDB ratings is between 5.5161962 and 6.551379.</p>
</blockquote>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC6.20)</strong> Reproduce the bootstrapping above using a sample of size 50 instead of 25. What changes do you see?</p>
<p><strong>(LC6.21)</strong> Reproduce the bootstrapping above using a sample of size 5 instead of 25. What changes do you see?</p>
<p><strong>(LC6.22)</strong> How does the sample size affect the analysis?</p>
<p><strong>(LC6.23)</strong> Why must bootstrap samples be the same size as the original sample?</p>
<hr />
<div id="review-of-bootstrapping" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Review of Bootstrapping</h3>
<p>We can summarize the process to generate a bootstrap distribution here in a series of steps that clearly identify the terminology we will use <span class="citation">(R. Lock et al. <a href="#ref-lock2012">2012</a>)</span>.</p>
<ul>
<li>Generate <code>bootstrap samples</code> by sampling with replacement from the original sample, using the same sample size.</li>
<li>Compute the statistic of interest, called a <code>bootstrap statistic</code>, for each of the bootstrap samples.</li>
<li>Collect the statistics for many bootstrap samples to create a <code>bootstrap distribution</code>.</li>
</ul>
<p>Visually, we can represent this process in the following diagram.</p>
<div class="figure" style="text-align: center"><span id="fig:bootstrapimg"></span>
<img src="images/bootstrap.png" alt="Bootstrapping diagram from Lock5 textbook" width="\textwidth" />
<p class="caption">
Figure 6.8: Bootstrapping diagram from Lock5 textbook
</p>
</div>
</div>
</div>
<div id="whats-to-come-3" class="section level2">
<h2><span class="header-section-number">6.4</span> What’s to come?</h2>
<p>This chapter has served as an introduction into inferential techniques that will be discussed in greater detail in Chapter <a href="7-hypo.html#hypo">7</a> for hypothesis testing and in Chapter <a href="8-ci.html#ci">8</a> for confidence intervals. In these chapters, we will see how we can use a related concept of <strong>resampling</strong> when working with the distributions of two groups. All of these concepts will be further reinforced in Chapter <a href="9-regress.html#regress">9</a> as well.</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-salsburg2001">
<p>Salsburg, David. 2001. <em>The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century</em>. First Edition. New York, NY: W.H. Freeman.</p>
</div>
<div id="ref-rds2016">
<p>Grolemund, Garrett, and Hadley Wickham. 2016. <em>R for Data Science</em>. <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a>.</p>
</div>
<div id="ref-usedtor2016">
<p>Ismay, Chester. 2016. <em>Getting Used to R, RStudio, and R Markdown</em>. <a href="http://ismayc.github.io/rbasics-book" class="uri">http://ismayc.github.io/rbasics-book</a>.</p>
</div>
<div id="ref-lock2012">
<p>Lock, Robin, Patti Frazer Lock, Kari Lock Morgan, Eric F. Lock, and Dennis F. Lock. 2012. <em>Statistics: UnLOCKing the Power of Data</em>. Wiley.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5-manip.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="7-hypo.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ismayc/moderndiver-source/edit/master/06-inference_basics.Rmd",
"text": null
},
"download": ["ismay.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
